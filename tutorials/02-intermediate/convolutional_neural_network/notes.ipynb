{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "> Building an training of the convolutional neural network\n",
    ">\n",
    "> **Table of Contents**\n",
    ">> 1. Import Libraries\n",
    ">>\n",
    ">> 2. Load Dataset\n",
    ">>\n",
    ">> 3. Define Model\n",
    ">>\n",
    ">> 4. Configure Device to Execute Model\n",
    ">>\n",
    ">> 5. Define Loss Function and Optimizer\n",
    ">>\n",
    ">> 6. Train Model\n",
    ">>\n",
    ">> 7. Test Model\n",
    ">>\n",
    ">> 8. Save Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Import libraries needed for the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch for machine learning capabilities\n",
    "import torch\n",
    "\n",
    "#import torchvision for image dataset (MNIST) and image transformations\n",
    "import torchvision"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With the libraries imported, we will now load the data to be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download and reference the training dataset\n",
    "training_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                           train=True,\n",
    "                                           transform=torchvision.transforms.ToTensor(),\n",
    "                                           download=True)\n",
    "\n",
    "#Download and reference the testing dataset\n",
    "testing_dataset = torchvision.datasets.MNIST(root='./data',\n",
    "                                             train=False,\n",
    "                                             transform=torchvision.transforms.ToTensor(),\n",
    "                                             download=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After loading the dataset, the next step is to specify the dataload to load the data in batches\n",
    ">\n",
    "> Because data will be being loaded in batches, we will define a hyperparameter for the batch size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the hyperparameter for the batch size (i.e., chunck size of the data being loaded)\n",
    "batch_size = 100\n",
    "\n",
    "#Define the DataLoader for the training dataset\n",
    "training_loader = torch.utils.data.DataLoader(dataset=training_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              drop_last=False)\n",
    "\n",
    "#Define the DataLoader for the training dataset\n",
    "testing_loader = torch.utils.data.DataLoader(dataset=testing_dataset,\n",
    "                                             batch_size=batch_size,\n",
    "                                             shuffle=False,\n",
    "                                             drop_last=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will now specify a convolutional neural network to take in some input vector, apply convolution operations, and output a probability vector\n",
    ">\n",
    "> When defining the model, we will use the module list (which is a list of module) to define the order of layers and use the sequential list (which is a cascading of modules) to define each convolutional layer\n",
    ">\n",
    "> The Convolutional Neural Network (CNN) consists of a pattern of different operations:\n",
    ">> **Convolution Operation** - colvolve around image by applying some filter (https://www.youtube.com/watch?v=eMXuk97NeSI&list=PLZDCDMGmelH-pHt-Ij0nImVrOmj8DYKbB)\n",
    ">>> **in_channels**: the number of features each pixel contains (will usually start at either 1 for B&W images or 3 for RGB images)\n",
    ">>>\n",
    ">>> **out_channels**: the number of features for each pixel in the output image (usually goot to start at a relatively small power of 2 such at 8 or 16 and then double the features on each layer until around 512 or 1024)\n",
    ">>>\n",
    ">>> **kernel_size**: the size of the filter; usually will always use a 3x3 filter except for the first filter which may be 3x3, 5x5, or even 7x7.\n",
    ">>>\n",
    ">>> **stride**: how big of a step the filter takes. A rule to not have lost data is to have the $ stride \\leq kernel_size $\n",
    ">>>\n",
    ">>> **padding**: the addition of 0-value features at the border of the input. Generally, to not have data lost, padding is added so that bigger kernel sizes/strides do not go out of bounds before convolving over all values in a row/column.\n",
    ">>\n",
    ">> **Batch Normalization**: perform normalization of the data within the layers rather than on the data itself to speed up the training process (https://www.baeldung.com/cs/batch-normalization-cnn)\n",
    ">>\n",
    ">> **Non-Linear Activation Function (ReLU)**: apply a non-linear activation so that the neural network can approximate any function (https://www.quora.com/Why-do-we-need-non-linear-activation-functions-in-a-neural-network)\n",
    ">>\n",
    ">> **Max Pooling**: Pooling of the layer, taking only the max pixel of a certain region; done to limit overall computation of the model. However, can achieve similar effect with a convolution operation with a larger stride (https://stats.stackexchange.com/questions/288261/why-is-max-pooling-necessary-in-convolutional-neural-networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the Convolutional Neural Network (CNN) Class\n",
    "class CNN(torch.nn.Module):\n",
    "    #CNN constructor function\n",
    "    def __init__(self, num_classes):\n",
    "        #First, call the constructor of the parent class\n",
    "        super(CNN, self).__init__()\n",
    "        #Specify the module list for the sequence of layers in the CNN\n",
    "        self.module_list = list()\n",
    "        #Define the first convolutional layer\n",
    "        layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            torch.nn.BatchNorm2d(16),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        #Append the convolutional layer to the module list\n",
    "        self.module_list.append(layer1)\n",
    "        #Define the second convolutional layer\n",
    "        layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(32),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        #Append the convolutional layer to the module list\n",
    "        self.module_list.append(layer2)\n",
    "        #Flatten the output into a single vector for input into a linear model\n",
    "        #Default parameters for Flattening layer leaves the first dimension untouched (i.e., the batches) and flattens everything else (i.e., the features)\n",
    "        self.module_list.append(torch.nn.Flatten())\n",
    "        #Append the linear layer to the model\n",
    "        self.module_list.append(torch.nn.Linear(7*7*32, num_classes))\n",
    "        #Log-Softmax used for numberical stability\n",
    "        self.module_list.append(torch.nn.LogSoftmax(dim=1))\n",
    "        #Lastly, convert the list object of modules into a ModuleList object (used so that PyTorch can detect the modules/parameters contained in the list)\n",
    "        self.layers = torch.nn.ModuleList(self.module_list)\n",
    "\n",
    "    #Define how the model applies forward propogation\n",
    "    def forward(self, x):\n",
    "        #Initially have the output be the passed data\n",
    "        out = x\n",
    "        #Loop through each layer in the model\n",
    "        for layer in self.layers:\n",
    "            #get the output for each layer, passing it to the next layer\n",
    "            out = layer(out)\n",
    "        #return the output\n",
    "        return(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With the CNN model now defined, we must instantiate the class to then train\n",
    ">\n",
    "> For this model, all we need to specify is the output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define hyperparameter for the output size\n",
    "num_classes = 10\n",
    "\n",
    "#Instantiate the model\n",
    "model = CNN(num_classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Device to Execute Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With the model defined, we can select the device to train the model on\n",
    ">\n",
    "> We will opt for the GPU via the CUDA library, but if it is unavailable, we will use the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the device for the model based on availability\n",
    "device = torch.device(\"cuda\" if(torch.cuda.is_available()) else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that the device is specified, we will move our instantiated model to that device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move the instantiated model to the best available device\n",
    "model = model.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function and Optimizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With the data acquired and the model specified, the next step if to define the loss function which we wish to minimize\n",
    ">\n",
    "> Since the model returns the log-softmax, we will use the NLL loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Will use the NLL loss function since the model returns the log-softmax vector\n",
    "lossFunction = torch.nn.NLLLoss()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, we will define the optimizer algorithm which defines how we will take steps to minimize the loss function\n",
    ">\n",
    "> Our optimizer will be the Adam optimizer\n",
    ">\n",
    "> For this optimizer, a hyperparameter we need to specify is the learning rate, which is essentially the step-size for the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the hyperparameter for the learning rate (step size)\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Use the Adam optimizer as the optimizer for minimizing the loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now, with our model defined, we can train it on our training data\n",
    ">\n",
    "> For our training data, we will need to define one last hyperparameter: the number of epochs to train with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.114906\n",
      "Epoch [1/5], Step [200/600], Loss: 0.039810\n",
      "Epoch [1/5], Step [300/600], Loss: 0.062347\n",
      "Epoch [1/5], Step [400/600], Loss: 0.070658\n",
      "Epoch [1/5], Step [500/600], Loss: 0.048792\n",
      "Epoch [1/5], Step [600/600], Loss: 0.070185\n",
      "Epoch [2/5], Step [100/600], Loss: 0.056447\n",
      "Epoch [2/5], Step [200/600], Loss: 0.013132\n",
      "Epoch [2/5], Step [300/600], Loss: 0.018252\n",
      "Epoch [2/5], Step [400/600], Loss: 0.047630\n",
      "Epoch [2/5], Step [500/600], Loss: 0.034676\n",
      "Epoch [2/5], Step [600/600], Loss: 0.050215\n",
      "Epoch [3/5], Step [100/600], Loss: 0.005318\n",
      "Epoch [3/5], Step [200/600], Loss: 0.009604\n",
      "Epoch [3/5], Step [300/600], Loss: 0.065311\n",
      "Epoch [3/5], Step [400/600], Loss: 0.040965\n",
      "Epoch [3/5], Step [500/600], Loss: 0.017391\n",
      "Epoch [3/5], Step [600/600], Loss: 0.009358\n",
      "Epoch [4/5], Step [100/600], Loss: 0.019390\n",
      "Epoch [4/5], Step [200/600], Loss: 0.028005\n",
      "Epoch [4/5], Step [300/600], Loss: 0.099064\n",
      "Epoch [4/5], Step [400/600], Loss: 0.023662\n",
      "Epoch [4/5], Step [500/600], Loss: 0.009371\n",
      "Epoch [4/5], Step [600/600], Loss: 0.058515\n",
      "Epoch [5/5], Step [100/600], Loss: 0.006559\n",
      "Epoch [5/5], Step [200/600], Loss: 0.032635\n",
      "Epoch [5/5], Step [300/600], Loss: 0.045028\n",
      "Epoch [5/5], Step [400/600], Loss: 0.025537\n",
      "Epoch [5/5], Step [500/600], Loss: 0.003376\n",
      "Epoch [5/5], Step [600/600], Loss: 0.023136\n"
     ]
    }
   ],
   "source": [
    "#Define the hyperparameter for the number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "#Specify the number of steps total in each epoch\n",
    "total_steps = len(training_loader)\n",
    "\n",
    "#Loop through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    #loop through each batch within each epoch\n",
    "    for i, (images, labels) in enumerate(training_loader):\n",
    "        #move images to configured device for best performance\n",
    "        images = images.to(device)\n",
    "        #move labels to configured device for best performance\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #perform a forward propogation on the model using the data in the batch\n",
    "        outputs = model(images)\n",
    "        #compute the current loss if the model using the outputs from the forward propogation\n",
    "        loss = lossFunction(outputs, labels)\n",
    "\n",
    "        #reset the gradient vector of the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        #perform backward propogation to compute the gradient\n",
    "        loss.backward()\n",
    "        #perform a single step in accordance to our hyperparameter (learning rate = 0.001) and optimizer algorithm (Adam)\n",
    "        optimizer.step()\n",
    "\n",
    "        #print the new loss for the model after every 100 steps are taken\n",
    "        if((i+1)%100 == 0):\n",
    "            #print relevent information about the current progress made during training to the console\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_steps}], Loss: {loss.item():4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have trained our model, the next step is to test the model against data it has never seen before (i.e., the testing data)\n",
    ">\n",
    "> Before testing, set the model to evaluation mode\n",
    ">\n",
    "> Model evaluation mode is used to change the forward method in the model to a form that is more proper for testing rather than training\n",
    ">\n",
    "> Model evaluation mode will disable drop out (random eactivation of neurons) and computes statistics over the entire dataset rather than each batch\n",
    ">\n",
    "> To return to training mode, use model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "    (3): Linear(in_features=1568, out_features=10, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Model Evaluation mode does not turn off gradient computation, so we will still need to turn it off while training for increased testing speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of the model on the 10,000 images: 98.81%\n"
     ]
    }
   ],
   "source": [
    "#Turn gradient compuation off while testing (not needed - wasted computation)\n",
    "with torch.no_grad():\n",
    "    #initiallize counter variables for the total and correct number of predictions\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    #loop through each batch and make predictions according to the trained model\n",
    "    for images, labels in testing_loader:\n",
    "        #move images to configured device for best performance\n",
    "        images = images.to(device)\n",
    "        #move labels to configured device for best performance\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        #perform forward propogation using the testing data on the model\n",
    "        outputs = model(images)\n",
    "\n",
    "        #the classs with the highest probability will be the classification by the model\n",
    "        probability, predicted_class = torch.max(outputs.data, dim=1)\n",
    "\n",
    "        #add to the total predictions counter\n",
    "        total_predictions += labels.size(dim=0)\n",
    "        #add to the total predictions that were correct\n",
    "        #the number of correct predictions are the sum of components in a boolean list, here the predicted class matched the specified label\n",
    "        correct_predictions += (predicted_class == labels).sum().item()\n",
    "\n",
    "    #lastly, print the accuracy of the model\n",
    "    print(f\"Test accuracy of the model on the 10,000 images: {100*correct_predictions/total_predictions}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Now that we have trained and tested the model, the final step is to save the trained model to load and run at another time or on another device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the trained model checkpoint\n",
    "torch.save(model.state_dict(), \"model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonVirtualEnvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
